# RF_app_v14.py
# [ìˆ˜ì •] PDP ìƒì„± ì‹œ Key ì˜¤ë¥˜ í•´ê²° ('values' -> feat)
# [ìˆ˜ì •] í°íŠ¸ ë¡œì§ ê°•í™”: (0) ì•± ë¡œì»¬ ê²½ë¡œì˜ í°íŠ¸ â†’ (1) ì—…ë¡œë“œ TTF â†’ (2) GitHub ...

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io, os, tempfile
from matplotlib import font_manager

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import r2_score, accuracy_score
from sklearn.inspection import partial_dependence
from sklearn.preprocessing import LabelEncoder

# ===== ìœ í‹¸: ê°„ë‹¨ ìŠ¤ë¬´ë”© í•¨ìˆ˜ (moving average) =====
def smooth_1d(y, window=5):
    y = np.asarray(y)
    if len(y) <= window: return y
    w = np.ones(window) / window
    return np.convolve(y, w, mode="same")

# ===== í°íŠ¸ ì„¤ì • í•¨ìˆ˜ (ê°œì„ ) =====
def set_korean_font(user_font_path=None):
    # 0) [ì¶”ê°€] ì•±ê³¼ í•¨ê»˜ ë°°í¬ëœ ë¡œì»¬ í°íŠ¸ íŒŒì¼ì„ ê°€ì¥ ë¨¼ì € í™•ì¸
    local_font_filename = 'NotoSansKR-Regular.otf'
    if os.path.exists(local_font_filename):
        font_manager.fontManager.addfont(local_font_filename)
        fname = font_manager.FontProperties(fname=local_font_filename).get_name()
        plt.rcParams["font.family"] = fname
        plt.rcParams["axes.unicode_minus"] = False
        return fname

    # 1) ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ í°íŠ¸
    if user_font_path and os.path.exists(user_font_path):
        font_manager.fontManager.addfont(user_font_path)
        fname = font_manager.FontProperties(fname=user_font_path).get_name()
        plt.rcParams["font.family"] = fname
        plt.rcParams["axes.unicode_minus"] = False
        return fname

    # 2) GitHub NotoSansKR ìë™ ë¡œë“œ ì‹œë„
    try:
        import requests
        url = "https://github.com/google/fonts/raw/main/ofl/notosanskr/NotoSansKR-Regular.otf"
        resp = requests.get(url, timeout=5)
        resp.raise_for_status()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".otf") as tmpf:
            tmpf.write(resp.content)
            remote_path = tmpf.name
        font_manager.fontManager.addfont(remote_path)
        fname = font_manager.FontProperties(fname=remote_path).get_name()
        plt.rcParams["font.family"] = fname
        plt.rcParams["axes.unicode_minus"] = False
        return fname
    except Exception:
        pass

    # 3) ë¡œì»¬ í•œê¸€ í°íŠ¸ íƒìƒ‰
    candidates = ["Malgun Gothic", "AppleGothic", "NanumGothic", "Noto Sans CJK KR", "Noto Sans KR", "Source Han Sans KR"]
    available = {f.name for f in font_manager.fontManager.ttflist}
    for name in candidates:
        if name in available:
            plt.rcParams["font.family"] = name
            plt.rcParams["axes.unicode_minus"] = False
            return name

    plt.rcParams["axes.unicode_minus"] = False
    return None

# ===== Streamlit ê¸°ë³¸ ì„¤ì • =====
st.set_page_config(page_title="ëœë¤í¬ë ˆìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡/ë¶„ë¥˜ ì›¹ì•±", layout="wide")
st.title("ëœë¤í¬ë ˆìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡/ë¶„ë¥˜ ì›¹ì•±")

# ===== ì‚¬ì´ë“œë°” =====
st.sidebar.header("ì˜µì…˜")

font_file = st.sidebar.file_uploader("í•œê¸€ í°íŠ¸ TTF ì—…ë¡œë“œ(ì„ íƒ)", type=["ttf"])
font_path = None
if font_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".ttf") as tmp:
        tmp.write(font_file.read())
        font_path = tmp.name

applied_font = set_korean_font(font_path)
if (not applied_font) and (font_file is None):
    st.sidebar.warning("ì‹œìŠ¤í…œ/ì›ê²© í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•±ì— í¬í•¨ëœ NotoSansKR í°íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

test_size = st.sidebar.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.8, 0.2, 0.05)
st.sidebar.caption(f"í˜„ì¬ ì„¤ì •: í•™ìŠµ ë°ì´í„° {100 - test_size*100:.0f}% / í…ŒìŠ¤íŠ¸ ë°ì´í„° {test_size*100:.0f}%")

# ===== íŒŒì¼ ì—…ë¡œë“œ =====
uploaded = st.file_uploader("CSV / XLSX / XLS íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"])
if uploaded is None:
    st.info("CSV, XLSX, XLS íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (.xlsì€ xlrd<2.0 í•„ìš”)")
    st.stop()

# ... (íŒŒì¼ ì½ê¸° ë° ì „ì²˜ë¦¬ ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ) ...
file_name = uploaded.name.lower()
file_bytes = uploaded.read()
df = None
try:
    if file_name.endswith(".csv"):
        read_ok = False
        for enc in ["utf-8-sig", "utf-8", "cp949"]:
            try:
                df = pd.read_csv(io.BytesIO(file_bytes), encoding=enc)
                read_ok = True; break
            except Exception: continue
        if not read_ok: st.error("CSV ì¸ì½”ë”©ì„ íŒë…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
    elif file_name.endswith((".xlsx", ".xls")):
        try: xls = pd.ExcelFile(io.BytesIO(file_bytes))
        except Exception as e: st.error(f"ì—‘ì…€ íŒŒì¼ ì—´ê¸° ì˜¤ë¥˜: {e}\n.xls íŒŒì¼ì€ 'pip install xlrd<2.0' í•„ìš”"); st.stop()
        sheet = st.selectbox("ë¶ˆëŸ¬ì˜¬ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=xls.sheet_names, index=0)
        df = pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet)
    else: st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."); st.stop()
except Exception as e: st.error(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}"); st.stop()

st.success(f"ë¡œë“œëœ ë°ì´í„° í˜•íƒœ: {df.shape}")
if df.shape[0] == 0 or df.shape[1] == 0: st.warning("ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."); st.stop()
st.dataframe(df.head(30))

df = df.replace(["#DIV/0!", "NaN", "nan", ""], np.nan)
for col in df.columns:
    if df[col].dtype == object:
        try:
            df[col] = df[col].astype(str).str.replace(",", "", regex=False)
            df[col] = pd.to_numeric(df[col], errors="ignore")
        except Exception: pass

target_col = st.selectbox("ì˜ˆì¸¡/ë¶„ë¥˜í•  ëª©í‘œ ë³€ìˆ˜(íƒ€ê¹ƒ)ì„ ì„ íƒí•˜ì„¸ìš”", df.columns)
if not target_col: st.stop()

df = df.dropna(subset=[target_col])
X = df.drop(columns=[target_col])
y = df[target_col]
X = X.dropna(axis=1, how="all")
data = pd.concat([X, y], axis=1).dropna()
X = data.drop(columns=[target_col])
y = data[target_col]

dropped_cols = []
for col in list(X.columns):
    if X[col].dtype == object:
        if X[col].nunique() <= 50:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        else:
            dropped_cols.append(col)
            X = X.drop(columns=[col])
if dropped_cols: st.info(f"â„¹ï¸ ê³ ìœ ê°’ì´ 50ê°œë¥¼ ì´ˆê³¼í•˜ì—¬ ë‹¤ìŒ ë³€ìˆ˜ëŠ” ë¶„ì„ì—ì„œ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤: **{', '.join(dropped_cols)}**")

task = "regression"
if not np.issubdtype(y.dtype, np.number) or (y.nunique() <= 10 and y.dtype != float):
    task = "classification"
if task == "classification":
    y = LabelEncoder().fit_transform(y.astype(str))
else:
    y = pd.to_numeric(y, errors="coerce")
    keep = ~pd.isna(y)
    X, y = X.loc[keep], y.loc[keep]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1) if task == "regression" else RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

st.subheader("ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼")
if task == "regression":
    r2 = r2_score(y_test, model.predict(X_test))
    st.success(f"ğŸ”¹ ì„¤ëª…ë ¥ (RÂ²): {r2:.3f}")
else:
    acc = accuracy_score(y_test, model.predict(X_test))
    st.success(f"ğŸ”¹ ì •í™•ë„ (Accuracy): {acc:.3f}")

st.subheader("ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance)")
importances = pd.DataFrame({"ë³€ìˆ˜": X.columns.astype(str), "ì¤‘ìš”ë„": model.feature_importances_}).sort_values("ì¤‘ìš”ë„", ascending=False)
st.dataframe(importances)
fig, ax = plt.subplots(figsize=(6, 4))
top_n = min(15, len(importances))
ax.barh(importances["ë³€ìˆ˜"].head(top_n)[::-1], importances["ì¤‘ìš”ë„"].head(top_n)[::-1])
ax.set_xlabel("ì¤‘ìš”ë„"); ax.set_ylabel("ë³€ìˆ˜"); ax.set_title("ë³€ìˆ˜ ì¤‘ìš”ë„ ìƒìœ„ í•­ëª©")
for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):
    item.set_fontfamily(plt.rcParams["font.family"])
st.pyplot(fig)

# ===== PDP (ì˜¤ë¥˜ ìˆ˜ì •) =====
st.subheader("ë³€ìˆ˜ë³„ ì˜í–¥ ê·¸ë˜í”„ (PDP)")
pdp_candidates = importances["ë³€ìˆ˜"].tolist()
default_vars = pdp_candidates[:4]
selected_vars = st.multiselect("PDPë¡œ í™•ì¸í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", pdp_candidates, default=default_vars)

if not selected_vars:
    st.info("ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´ ê°œë³„ ì˜ì¡´ë„ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
else:
    cols = 2
    rows = int(np.ceil(len(selected_vars) / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(8, 3 * rows))
    axes = np.atleast_1d(axes).flatten()

    for i, feat in enumerate(selected_vars):
        ax_i = axes[i]
        try:
            pdp_result = partial_dependence(model, X_test, features=feat, kind="average")
            # [ìˆ˜ì •] í‚¤ë¥¼ 'values'ê°€ ì•„ë‹Œ ë³€ìˆ˜ëª…(feat)ìœ¼ë¡œ ì ‘ê·¼
            x_values = pdp_result[feat][0]
            y_values = pdp_result['average'][0]
            
            y_smooth = smooth_1d(y_values)
            
            ax_i.plot(x_values, y_smooth, "-", linewidth=2)
            ax_i.scatter(x_values, y_values, s=10, color="gray", alpha=0.5)
            ax_i.set_title(str(feat)); ax_i.set_xlabel(str(feat)); ax_i.set_ylabel("Partial dependence")
            
            for item in ([ax_i.title, ax_i.xaxis.label, ax_i.yaxis.label] + ax_i.get_xticklabels() + ax_i.get_yticklabels()):
                item.set_fontfamily(plt.rcParams["font.family"])
        except Exception as e:
            ax_i.set_visible(False)
            st.warning(f"PDP ìƒì„± ì¤‘ ì˜¤ë¥˜({feat}): {e}")

    for j in range(len(selected_vars), len(axes)):
        axes[j].set_visible(False)

    plt.tight_layout()
    st.pyplot(fig)

st.caption("â€» ê·¸ë˜í”„ í•œê¸€ì´ ê¹¨ì§€ë©´ í°íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ì•±ì— í¬í•¨ëœ í°íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
