# RF_app_v12.py
# - CSV/XLSX/XLS ì§€ì› + ì‹œíŠ¸ ì„ íƒ
# - í•œê¸€ í°íŠ¸: (1) ì—…ë¡œë“œ TTF â†’ (2) GitHub NotoSansKR ìë™ ë¡œë“œ â†’ (3) ë¡œì»¬ í°íŠ¸ íƒìƒ‰
# - í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ ìŠ¬ë¼ì´ë” (ê¸°ë³¸ 0.8)
# - ì„±ëŠ¥: ì„¤ëª…ë ¥(RÂ²) ë˜ëŠ” ì •í™•ë„(Accuracy)
# - PDP: multiselectë¡œ ë³€ìˆ˜ ì„ íƒ, 2ê°œì”© ë°°ì¹˜
#        + moving-average ìŠ¤ë¬´ë”©ìœ¼ë¡œ ê³¡ì„  + ì›ë˜ PDP ì ë„ ê°™ì´ í‘œì‹œ

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import io, os, tempfile
from matplotlib import font_manager

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import r2_score, accuracy_score
from sklearn.inspection import PartialDependenceDisplay
from sklearn.preprocessing import LabelEncoder


# ===== ìœ í‹¸: ê°„ë‹¨ ìŠ¤ë¬´ë”© í•¨ìˆ˜ (moving average) =====
def smooth_1d(y, window=5):
    """1ì°¨ì› ë°°ì—´ yë¥¼ ì´ë™í‰ê· ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë§Œë“­ë‹ˆë‹¤."""
    y = np.asarray(y)
    if len(y) <= window:
        return y
    w = np.ones(window) / window
    return np.convolve(y, w, mode="same")


# ===== í°íŠ¸ ì„¤ì • í•¨ìˆ˜ =====
def set_korean_font(user_font_path=None):
    """
    í•œê¸€ í°íŠ¸ë¥¼ ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •:
    1) ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ TTF
    2) GitHubì˜ NotoSansKR ìë™ ë‹¤ìš´ë¡œë“œ
    3) ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ í•œê¸€ í°íŠ¸ íƒìƒ‰
    """
    # 1) ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ í°íŠ¸
    if user_font_path and os.path.exists(user_font_path):
        font_manager.fontManager.addfont(user_font_path)
        fname = font_manager.FontProperties(fname=user_font_path).get_name()
        plt.rcParams["font.family"] = fname
        plt.rcParams["axes.unicode_minus"] = False
        return fname

    # 2) GitHub NotoSansKR ìë™ ë¡œë“œ ì‹œë„ (ì¸í„°ë„· ì—°ê²° í•„ìš”)
    try:
        import requests

        url = (
            "https://github.com/google/fonts/raw/main/ofl/notosanskr/"
            "NotoSansKR-Regular.otf"
        )
        resp = requests.get(url, timeout=5)
        resp.raise_for_status()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".otf") as tmpf:
            tmpf.write(resp.content)
            remote_path = tmpf.name
        font_manager.fontManager.addfont(remote_path)
        fname = font_manager.FontProperties(fname=remote_path).get_name()
        plt.rcParams["font.family"] = fname
        plt.rcParams["axes.unicode_minus"] = False
        return fname
    except Exception:
        # ì¸í„°ë„·ì´ ì—†ê±°ë‚˜ requests ì„¤ì¹˜ ë¬¸ì œ ë“±ì€ ì¡°ìš©íˆ ë¬´ì‹œ
        pass

    # 3) ë¡œì»¬ í•œê¸€ í°íŠ¸ íƒìƒ‰
    candidates = [
        "Malgun Gothic",
        "AppleGothic",
        "NanumGothic",
        "Noto Sans CJK KR",
        "Noto Sans KR",
        "Source Han Sans KR",
    ]
    available = {f.name for f in font_manager.fontManager.ttflist}
    for name in candidates:
        if name in available:
            plt.rcParams["font.family"] = name
            plt.rcParams["axes.unicode_minus"] = False
            return name

    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ (í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
    plt.rcParams["axes.unicode_minus"] = False
    return None


# ===== Streamlit ê¸°ë³¸ ì„¤ì • =====
st.set_page_config(page_title="ëœë¤í¬ë ˆìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡/ë¶„ë¥˜ ì›¹ì•±", layout="wide")
st.title("ëœë¤í¬ë ˆìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡/ë¶„ë¥˜ ì›¹ì•±")

# ===== ì‚¬ì´ë“œë°”: í°íŠ¸ ì—…ë¡œë“œ + í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ ì„¤ì • =====
st.sidebar.header("ì˜µì…˜")

font_file = st.sidebar.file_uploader("í•œê¸€ í°íŠ¸ TTF ì—…ë¡œë“œ(ì„ íƒ)", type=["ttf"])
font_path = None
if font_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".ttf") as tmp:
        tmp.write(font_file.read())
        font_path = tmp.name

applied_font = set_korean_font(font_path)
if (not applied_font) and (font_file is None):
    st.sidebar.warning(
        "ì‹œìŠ¤í…œì—ì„œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
        "ê·¸ë˜í”„ í•œê¸€ì´ ê¹¨ì§€ë©´ TTFë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."
    )

test_size = st.sidebar.slider(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", min_value=0.1, max_value=0.8, value=0.8, step=0.05
)
st.sidebar.caption("â€» í•™ìŠµ:í…ŒìŠ¤íŠ¸ = 1 - ë¹„ìœ¨ : ë¹„ìœ¨ (ì˜ˆ: 0.8 â†’ 2:8)")

# ===== íŒŒì¼ ì—…ë¡œë“œ =====
uploaded = st.file_uploader("CSV / XLSX / XLS íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"])
if uploaded is None:
    st.info("CSV, XLSX, XLS íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (.xlsì€ xlrd<2.0 í•„ìš”)")
    st.stop()

file_name = uploaded.name.lower()
file_bytes = uploaded.read()
df = None

# ===== íŒŒì¼ ì½ê¸° =====
try:
    if file_name.endswith(".csv"):
        read_ok = False
        for enc in ["utf-8-sig", "utf-8", "cp949"]:
            try:
                df = pd.read_csv(io.BytesIO(file_bytes), encoding=enc)
                read_ok = True
                break
            except Exception:
                continue
        if not read_ok:
            st.error("CSV ì¸ì½”ë”©ì„ íŒë…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (utf-8 / cp949 ë“± í™•ì¸)")
            st.stop()

    elif file_name.endswith((".xlsx", ".xls")):
        try:
            xls = pd.ExcelFile(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(
                "ì—‘ì…€ íŒŒì¼ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"
                "ë§Œì•½ .xls íŒŒì¼ì´ë¼ë©´ 'pip install xlrd<2.0' ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\n"
                f"ì˜¤ë¥˜: {e}"
            )
            st.stop()
        sheet = st.selectbox("ë¶ˆëŸ¬ì˜¬ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=xls.sheet_names, index=0)
        df = pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet)
    else:
        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()

# ===== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° =====
st.success(f"ë¡œë“œëœ ë°ì´í„° í˜•íƒœ: {df.shape}")
if df.shape[0] == 0 or df.shape[1] == 0:
    st.warning("ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    st.stop()
st.dataframe(df.head(30))

# ===== ì „ì²˜ë¦¬ =====
df = df.replace(["#DIV/0!", "NaN", "nan", ""], np.nan)
for col in df.columns:
    if df[col].dtype == object:
        try:
            df[col] = df[col].astype(str).str.replace(",", "", regex=False)
            df[col] = pd.to_numeric(df[col], errors="ignore")
        except Exception:
            pass

# ===== íƒ€ê¹ƒ ì„ íƒ =====
target_col = st.selectbox("ì˜ˆì¸¡/ë¶„ë¥˜í•  ëª©í‘œ ë³€ìˆ˜(íƒ€ê¹ƒ)ì„ ì„ íƒí•˜ì„¸ìš”", df.columns)
if not target_col:
    st.stop()

df = df.dropna(subset=[target_col])
X = df.drop(columns=[target_col])
y = df[target_col]

X = X.dropna(axis=1, how="all")
data = pd.concat([X, y], axis=1).dropna()
X = data.drop(columns=[target_col])
y = data[target_col]

# ===== ë²”ì£¼í˜• ê°„ë‹¨ ì¸ì½”ë”© =====
for col in list(X.columns):
    if X[col].dtype == object:
        if X[col].nunique() <= 50:
            X[col] = LabelEncoder().fit_transform(X[col].astype(str))
        else:
            X = X.drop(columns=[col])

# ===== ê³¼ì œ ìœ í˜• íŒë³„ =====
task = "regression"
if not np.issubdtype(y.dtype, np.number):
    task = "classification"
elif y.nunique() <= 10 and y.dtype != float:
    task = "classification"

if task == "classification":
    y = LabelEncoder().fit_transform(y.astype(str))
else:
    y = pd.to_numeric(y, errors="coerce")
    keep = ~pd.isna(y)
    X, y = X.loc[keep], y.loc[keep]

# ===== í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  =====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=42
)

# ===== ëª¨ë¸ =====
if task == "regression":
    model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
else:
    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# ===== ì„±ëŠ¥ í‘œì‹œ =====
st.subheader("ëª¨ë¸ ì„±ëŠ¥ ê²°ê³¼")
if task == "regression":
    r2 = r2_score(y_test, model.predict(X_test))
    st.success(f"ğŸ”¹ ì„¤ëª…ë ¥ (RÂ²): {r2:.3f}")
else:
    acc = accuracy_score(y_test, model.predict(X_test))
    st.success(f"ğŸ”¹ ì •í™•ë„ (Accuracy): {acc:.3f}")

# ===== ë³€ìˆ˜ ì¤‘ìš”ë„ =====
st.subheader("ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance)")
importances = pd.DataFrame(
    {"ë³€ìˆ˜": X.columns.astype(str), "ì¤‘ìš”ë„": model.feature_importances_}
).sort_values("ì¤‘ìš”ë„", ascending=False)
st.dataframe(importances)

fig, ax = plt.subplots(figsize=(6, 4))
top_n = min(15, len(importances))
ax.barh(
    importances["ë³€ìˆ˜"].head(top_n)[::-1],
    importances["ì¤‘ìš”ë„"].head(top_n)[::-1],
)
ax.set_xlabel("ì¤‘ìš”ë„")
ax.set_ylabel("ë³€ìˆ˜")
ax.set_title("ë³€ìˆ˜ ì¤‘ìš”ë„ ìƒìœ„ í•­ëª©")
for item in (
    [ax.title, ax.xaxis.label, ax.yaxis.label]
    + ax.get_xticklabels()
    + ax.get_yticklabels()
):
    item.set_fontfamily(plt.rcParams["font.family"])
st.pyplot(fig)

# ===== PDP (ì‚¬ìš©ì ì„ íƒí˜• + ê³¡ì„  ìŠ¤ë¬´ë”©) =====
st.subheader("ë³€ìˆ˜ë³„ ì˜í–¥ ê·¸ë˜í”„ (PDP)")
pdp_candidates = importances["ë³€ìˆ˜"].tolist()
default_vars = pdp_candidates[:4]
selected_vars = st.multiselect(
    "PDPë¡œ í™•ì¸í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
    pdp_candidates,
    default=default_vars,
)

if len(selected_vars) == 0:
    st.info("ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´ ê°œë³„ ì˜ì¡´ë„ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
else:
    cols = 2
    rows = int(np.ceil(len(selected_vars) / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(8, 3 * rows))
    axes = np.atleast_1d(axes).flatten()

    for i, feat in enumerate(selected_vars):
        ax_i = axes[i]
        try:
            # 1) ìš°ì„  sklearnì´ PDPë¥¼ ax_i ìœ„ì— ê·¸ë¦¬ê²Œ í•¨
            disp = PartialDependenceDisplay.from_estimator(
                model, X_test, features=[feat], kind="average", ax=ax_i
            )

            # 2) ë°©ê¸ˆ ê·¸ë ¤ì§„ ì„  ë°ì´í„°ë¥¼ ì¶•ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜´
            if not ax_i.lines:
                # í˜¹ì‹œë¼ë„ ì„ ì´ ì—†ë‹¤ë©´ ê·¸ëƒ¥ íŒ¨ìŠ¤
                continue

            line_obj = ax_i.lines[0]  # ì²« ë²ˆì§¸ ì„ 
            x = line_obj.get_xdata()
            y = line_obj.get_ydata()

            # 3) ìŠ¤ë¬´ë”© ì ìš©
            y_smooth = smooth_1d(y, window=5)

            # 4) ê¸°ì¡´ ì„ /í‹± ë§‰ëŒ€ ì œê±° í›„ ë‹¤ì‹œ ê·¸ë¦¼
            ax_i.cla()
            ax_i.plot(x, y_smooth, "-", linewidth=2)
            ax_i.scatter(x, y, s=10, color="gray", alpha=0.5)
            ax_i.set_title(str(feat), fontfamily=plt.rcParams["font.family"])
            ax_i.set_xlabel(str(feat), fontfamily=plt.rcParams["font.family"])
            ax_i.set_ylabel(
                "Partial dependence", fontfamily=plt.rcParams["font.family"]
            )

            for item in (
                [ax_i.title, ax_i.xaxis.label, ax_i.yaxis.label]
                + ax_i.get_xticklabels()
                + ax_i.get_yticklabels()
            ):
                item.set_fontfamily(plt.rcParams["font.family"])

        except Exception as e:
            ax_i.set_visible(False)
            st.warning(f"PDP ìƒì„± ì¤‘ ì˜¤ë¥˜({feat}): {e}")

    # ë‚¨ëŠ” ì¶• ìˆ¨ê¸°ê¸°
    # (selected_varsê°€ len 1ì¼ ë•Œë¥¼ ëŒ€ë¹„í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    last_index = len(selected_vars) - 1
    for j in range(last_index + 1, len(axes)):
        axes[j].set_visible(False)

    plt.tight_layout()
    st.pyplot(fig)

st.caption(
    "â€» ê·¸ë˜í”„ í•œê¸€ì´ ê¹¨ì§€ë©´ ì‚¬ì´ë“œë°”ì—ì„œ í•œê¸€ TTFë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜, "
    "ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš” (NotoSansKR ìë™ ë¡œë“œ)."
)
